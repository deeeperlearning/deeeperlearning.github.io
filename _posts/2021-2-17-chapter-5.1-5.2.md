# 5.1 Learning Algorithms

학습 알고리즘이란 어떤 task들의 class $T$에 대한 알고리즘의 성능이 $P$라고 할 때, 경험 $E$를 이용하여 $P$를 향상시킬 수 있는 알고리즘을 말한다. 이 장에서는 $T$, $P$, $E$에 대하여 소개한 후 간단한 예시인 linear regression에 적용하는 과정을 소개한다.

## 5.1.1 The Task, $T$

학습 알고리즘을 이용하여 해결할 수 있는 task는 여러가지가 있다. 여기에서는 그 중 가장 자주 등장하는 task들의 예시를 소개한다.

- Classification
    - Input을 여러개의 class 중 하나로 분류하는 문제.
- Classification with missing input
    - Classification 이지만 input 중 일부가 없을 수 있는 문제.
    - Input 차원이 $n$이라고 할 때, input이 소실될 수 있는 모든 가능성을 고려한다면 $2^n$개의 함수를 알아야 한다. 하지만 학습 알고리즘을 사용하면, marginal distribution을 학습하여 하나의 함수만으로 추론할 수 있다.
    - 이러한 문제는 주로 medical domain같이 data의 값이 비싸고 얻기 어려운 분야에서 에서 풀어야 하는 경우가 많다.
- Regression
    - 분류의 continuous 버전. Input에 대하여 값을 예측하는 문제.
- Transcription
    - 사진 등의 구조적이지 않은 input에 대하여 텍스트를 뽑아내는 task들. 예를들어 사진에서 문장을 추출하는 task, 또는 음성인식이 transcription에 해당한다.
- Machine translation
    - 자연어 사이의 기계번역 등.
- Structured output
    - 알고리즘의 출력이 벡터이고 벡터의 성분들 사이에 중요한 관계가 있는 task. 다른 task들 중 여럿을 포함하는 넓은 범주이다.
    - 예를들어 input이 이미지이고 output이 이미지에 부여할 제목(자연어)인 경우도 이 task에 해당한다.
- Anomaly detection
    - 알고리즘이 데이터로부터 이상치를 찾아내는 task.
- Synthesis and sampling
    - Generative model들이 여기에 해당한다.
- Imputation of missing values
    - Input $\vec{x} \in R^n$ 중 빠져있는 일부 성분들을 예측하는 task.
- Denoising
    - Input에 포함된 noise를 제거하는 알고리즘.
    - 일반적으로 noise의 source를 모르기 때문에 데이터로부터 추론해야 한다.
- Density estimation
    - 데이터의 확률 밀도함수 또는 확률 질량함수를 추정하는 문제.
    - 이론적으로 데이터의 분포를 추정했다면 위에 소개한 다를 문제들은 이미 풀었다고 봐도 무방하다.

## 5.1.2  The Performance Measure, $P$

- $P$를 측정하는 궁극적인 목표는 알고리즘이 실제로 사용될 때의 성능을 가늠하기 위함이다. 이를 위해 학습에 사용하지 않은 test 데이터셋에 대하여 $P$를 측정한다.
- $P$를 측정하는 방법을 일반화하기는 어렵다. 결국 $P$를 통해 측정하려 하는 것은 알고리즘의 오류율 (또는 정확도) 이다. ***5.1.1***에서 소개한 것 처럼 많은 종류의 task들이 있고, 각 task에 적합한 $P$가 있다.

## 5.1.3 The Experience, $E$

- $E$를 두 종류로 분류하자면 지도학습과 비지도학습이 있다.
    - 지도학습의 목표는 주어진 input에 대한 예측을 정확히 하는 것이다. 즉, 알고리즘이 $p(y|x)$를 학습하는 것이 목적이다. 지도학습에 사용되는 데이터셋에는 label이 존재한다. Classification, regression등의 task가 지도학습을 통해 해결 가능하다.
    - 비지도학습의 목표는 주어진 자료 집합에 존재하는 구조적인 특성이나 분포를 학습하는 것이다. 이 경우 데이터셋에 label이 없다. 알고리즘은 주어진 input들만을 이용하여 $p(x)$ 자체를 학습하는 것이 목표이다. Clustering같은 task가 비지도학습으로 해결할 수 있다.
- $E$를 지도학습과 비지도학습으로 나누기는 하지만, 엄밀하게 정의된 개념들은 아니다. 지도학습 문제를 비지도학습으로 변환할 수도, 그 반대도 가능하다.
    - 비지도학습은 여러개의 지도학습 문제로 쪼개는 것이 가능하다.
    $p(\vec{x}) = \prod_i p(x_i|x_1, x_2, ..., x_{i-1})$
    - 지도학습 역시 비지도학습 알고리즘을 통해 전체 분포 $p(x, y)$를 학습한 후 조건부 확률을 계산하는 식으로 추론이 가능하다.
    $p(y|x) = \frac{p(x, y)}{\sum_{y'}p(x, y')}$
- 이 외에도 준지도학습, 다중 인스턴스 학습, 강화학습 등의 학습 방법들도 존재한다.
    - 준지도학습의 경우 데이터셋의 일부에만 label이 있다.
    - 다중 인스턴스 학습(multi-instance learning)의 경우 데이터셋에 특정 부류의 샘플이 포함되어 있다는 정보는 있지만 label은 없다.
    - 강화학습은 데이터셋이 고정되어 있지 않고 주변 환경과 지속적으로 상호작용한다. 이 책에서는 다루지 않는다.
- 학습 알고리즘을 다룰 때 데이터셋을 design matrix로 표현하는 경우가 많다. Design matrix는 데이터를 행렬 형태로 모아놓은 것인데, $i$번째 데이터 샘플을 design matrix $X$의 $i$번째 row로 표현한다.
$X = [\vec{x}_1, \vec{x}_2, ...]^T$

## 5.1.4 Example: Linear Regression

지금까지 학습 알고리즘의 관점에서 task, performance measure, experience가 무엇인지 소개하였다. 이번에는 이 개념들을 적용하여 선형 회귀 모델을 기술해보려 한다. 즉, task가 regression인 경우이다. 우선 선형 회귀 모델은 아래와 같이 생겼다.

$$\hat{y} = \vec{w}^T \vec{x}$$

선형 회귀 모델의 학습은 적절한 $\vec{w}$를 찾는 것이다.

이제 design matrix $X$를 이용하여 선형 회귀 모델의 적절한 $\vec{w}$를 찾아보자. 여러가지 방법이 있지만, performance measure는 평균제곱오차를 사용하려 한다. 즉, 이제 목표는 $X$에 대하여 다음의 값을 줄이는 것이다.

$$\text{MSE} = \frac{1}{m} \sum_{i=1}^m(\hat{y} - y) \\ = \frac{1}{m} ||\hat{y} - y||_2^2$$

선형 회귀 문제의 경우 MSE를 미분하여 closed form solution을 얻을 수 있다.

$$\nabla_{\vec{w}} MSE = 0 \\ \Rightarrow \vec{w} = (X^TX)^{-1} X^Ty$$

물론 ***5.1.2***에서 소개한 것 처럼, 이 모델이 실제로 사용될 때 성능을 가늠하기 위해 design matrix를 $X^{train}, X^{test}$로 분리한 후 $X^{train}$을 이용하여 찾은 $\vec{w}^{train}$의 성능을 $X^{test}$에 대하여 확인하는 것이 바람직하다.

# 5.2 Capacity, Overfitting and Underfitting

이 장에서는 기계학습 모델의 수용력, 과적합, 과소적합에 대하여 다룬다. 약간 추상적인 면이 있지만 이러한 개념들을 알아두는 것이 이후의 기계학습 모델을 공부할 때 도움이 될 것 같다.

- 과소적합, 과대적합
    - ***5.1.2***에서 말한 것 처럼 학습 알고리즘의 궁극적인 목표는 test set에 대한 오차를 줄이는 것 이다. 즉, 우리는 기계학습 모델을 학습시키며 두 가지를 신경써야 한다.
        1. Training set에 대한 오차를 작게 만드는 능력
        2. Test set에 대한 오차를 작게 만드는 능력
    - 1번은 만족했지만 2번은 만족하지 못한 경우를 과적합, 그 반대인 경우를 과소적합이라 부른다.

![_config.yml]({{ site.baseurl }}/assets/ch5/overfitting.png)

- 모델의 수용력
    - 모델의 가설 공간이라고도 부른다.
    - 만약 모델의 표현 수용력이 너무 크다면 과적합이 발생할 가능성이 높고, 표현 수용력이 너무 작다면 과소적합이 발생할 가능성이 높다.
    - 최적화에 사용한 알고리즘의 한계 등으로 모델이 실제로 표현할 수 있는 것이 표현 수용력보다 작을 수 있으며, 이를 모델의 유효 수용력이라 한다. 이러한 모델의 수용력을 수치화하는 다양한 방법이 있으며 그 중 하나는 VC dimension(Vapnik & Chervonenkis dimension)이다.
    - 모델의 수용력은 주로 모델의 매개변수에 의존한다. 예를들어 regression 을 할 때 몇차항까지 사용할지 등이 이에 해당된다.
    - 이러한 논의들을 딥러닝에 바로 적용하기는 어렵다. 딥러닝에는 여러가지 nonconvex함수와 최적화 알고리즘들이 관여하는데, 이러한 상황에서의 최적화 문제를 아직 잘 이해하지 못했기 때문이다.
- Bayes error
    - 만약 우리가 정말 우연히 자료 생성의 실제 확률분포를 표현하는 모델을 발견했다고 하자. 하지만 이 경우에도 데이터셋에 노이즈가 존재하기 때문에 오차는 0이 아니다.
    - 즉, 이렇게 데이터 자체에 내재되어있는 오차를 베이즈 오차라고 부른다.

## 5.2.1 The No Free Lunch Theorem

통계이론에 따르면, 아주 이상적인 상황에서 기계학습 알고리즘과 모든 데이터포인트를 하나의 값으로 분류하는 모델의 성능은 동일하다. 이 장에서는 그럼에도 불구하고 기계학습 알고리즘이 현실세계에서 잘 작동하는 근거를 제시한다.

- 귀납추론의 한계
    - 귀납추론의 관점에서 생각해보면 유한한 크기의 데이터셋을 이용하여 일반적인 규칙을 알아내는 것은 논리적으로 모순이다.
    - 즉, 현실세계에서 기계 학습 알고리즘을 이용하여 일반적인 규칙을 알아내는 것은 불가능하다.
    - 기계학습은 이러한 문제점을 거의 대부분의 데이터에 대하여 정확할 가능성이 있는 규칙을 찾음으로써 피해간다. 즉, 확률적으로 옳을 가능성이 있는 규칙을 추론하는 것이다.
- 공짜 점심 없음 정리
    - 공짜 점심 없음 정리란, 모든 가능한 데이터 분포에 대해 모델의 평균 성능을 계산할 경우 아직 관측하지 못한 데이터에 대한 모델들의 성능은 모두 동일하다.
    - 기계학습 알고리즘에 기대하는 것은 아직 관측하지 못한 test data에 대하여 좋은 성능을 얻는 것이다. 이러한 관점에서 모든 데이터포인트를 하나의 값으로 분류하는 모델과 굉장히 복잡한 기계학습 알고리즘의 성능은 동일하다.
    - 하지만 현실에서 모든 데이터 분포에 대하여 모델의 성능을 평가하는 것은 불가능하므로 우리가 관측한 분포 내에서 (구체적인 task에 대하여) 상대적으로 잘 작동하는 기계학습 알고리즘을 만드는 것은 가능하다. 즉, 우리의 목표는 현실세계에서 잘 작동하는 모델을 찾아내는 것이다.

## 5.2.2 Regularization

- ***5.2***의 초입에서 기계학습 알고리즘의 궁극적인 목표는 일반화 오차를 작게 하는 것이라고 소개하였다. 그리고 이러한 일반화 오차를 알고리즘의 표현력 관점에서 설명하였다.
- ***5.2***에서 설명한 모델의 가설공간이란 함수들의 집함 정도로 생각하면 된다. 우리가 기계학습 알고리즘을 학습한다는 것은 최적화 알고리즘을 통해 가설공간의 한 함수를 골라내는 것이다. 즉, 가설공간이 너무 크면 과적합 된 모델을 찾아낼 가능성이, 가설공간이 너무 작으면 과소적합된 모델을 찾아낼 가능성이 크다.
- 하지만, 우리가 해결하려는 task에 대한 사전정보를 알고있다면 모델의 특정한 가설공간에 선호도를 부여하여 과적합을 예방할 수 있다. 기계학습에서는 특정한 형태의 penelty를 부여하여 가설공간에 선호도를 부여하는데, 이를 정칙화(regularization)이라고 부른다.
    - 추후에 등장하겠지만 이러한 정칙화 항은 maximum a posteriori를 통해 모델을 선택할 때 prior distribution에 해당한다. 즉, 모델이 대충 어떻게 생겼을지 미리 알고있다는 의미이다.
- 기계학습 알고리즘에서 자주 쓰이는 정칙화 항들이 있는데 두가지만 소개하려 한다.
    - $L_1$-regulariztion: 모델을 학습할 때 loss에 모델 파라미터들의 $L_1$-norm을 더해준다. 학습 과정에서 모델은 선형적으로 파라미터들을 작은 값으로 선택하려 하고 sparse한 모델이 학습된다. Maximum a posteriori 관점에서 prior distribution을 Laplace distribution으로 선택한 것과 같다. 선형 회귀 모델에 $L_1$-regulariztion을 적용한 예시가 아래 그림에 있다. Regularization의 강도 $\lambda$를 조절함에 따라 모델이 과소적합, 과적합 되는 것을 방지할 수 있다.
    - $L_2$-regulariztion: 모델을 학습할 때 loss에 모델 파라미터들의 $L_2$-norm을 더해준다. $L_1$-norm과 동일하게 학습 과정에서 모델은 파라미터들을 작은 값으로 선택하려 하지만 상대적으로 큰 파라미터들에 대하여 더 큰 penelty를 부여한다. 결론적으로 모델은 적당히 작은 파라미터들을 선택하게 된다. Maximum a posteriori 관점에서 prior distribution을 Gaussian distribution으로 선택한 것과 같다.

![_config.yml]({{ site.baseurl }}/assets/ch5/regularization.png)
