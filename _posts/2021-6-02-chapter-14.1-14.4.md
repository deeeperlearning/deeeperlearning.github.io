Autoencoder는 자기 네트워크의 입력을 출력으로 복사하도록 학습하는 모델이다.
모델 구조는 크게 encoder $f$, decoder $g$로 나뉘며 입력 x에 대하여 $x=g(f(x))$이 모델을 찾는것이 목표이다.
보통 입력을 근사적으로 재현하지만, 이 과정에서 데이터셋의 가치있는 정보를 latent vector $h$에(책에서는 $h$를 "code"라고 부름) 압축할 수 있다.

물론 아무렇게나 하면 되는건 아니고 $h$에 유용한 정보를 압축하기 위해 네트워크의 모양이나 loss등을 잘 설계해야 한다.


## 14.1 Undercomplete Autoencoders
입력 $x$의 차원보다 code $h$의 차원이 작은 autoencoder를 undercomplete이라 부른다.
Undercomplete autoencoder에 대하여 기억해야 할 몇 가지 내용은 다음과 같다.

- 입력 차원보다 작은 code 차원으로 데이터를 압축해야 하기 때문에 데이터셋에서 유용한 정보만 추리도록 학습된다.
- 비용함수는 MSE를 사용한다.
    - $L(x, g(f(x)))$
- Decoder $g$가 선형 함수이고 MSE loss를 사용하는 경우 PCA와 같은 subspace를 학습한다.
    - 즉, undercomplete autoencoder는 PCA를 비선형 공간으로 일반화 시킨 것.

위의 특징들은 네트워크의 capacity가 적당히 작아 autoencoder가 데이터셋의 유용한 정보만 압축할 수 있다고 가정한 것이다.
만약 네트워크의 capacity가 너무 커서 입력을 완벽하게 복제할 수 있다면 autoencoder는 유용한 정보를 추출할 수 없다.


## 14.2 Regularized Autoencoders
위에서 언급한 네트워크 capacity 관련한 문제는 hidden code의 차원이 입력과 같거나 큰 경우 더 발생하기 쉽다.
예를들어 hidden code의 차원이 입력보다 더 큰 경우 (overcomplete) encoder와 decoder가 모두 linear여도 데이터셋의 유용한 정보를 학습하지 않고 입력을 완벽히 재현할 수 있다.

이상적으로는 데이터의 복잡도를 잘 고려하여 code의 차원을 잘 선택한다면, autoencoder를 잘 학습할 수 있다.
하지만, code의 길이를 제한하는 대신 autoencoder의 loss에 정칙화 항을 추가하여 데이터셋의 유용한 정보를 추출할수도 있다.
이런 방법을 regularized autoencoder라고 부른다.

### 14.2.1 Sparse Autoencoders
Sparse autoencoder는 loss에 code의 sparsity penalty $\Omega(h)$를 넣은 것이다.
$$
L(x, g(f(x))) + \Omega(h)
$$

#### Sparsity penalty 해석

보통 regularizer는 MAP 관점에서 prior로 해석된다.

1. MAP: maximizing $p(\theta | x)$
2. maximizing $p(\theta | x)$ <=> maximizing $\log p(x|\theta) + \log p(\theta)$

2번 식을 보면 prior는 parameter에만 의존해야 한다.
하지만 sparsity penalty $\Omega(h) = \Omega(f(x))$는 parameter와 데이터에 모두 의존하기 때문에 prior로 해석할 수 없다.

대신에 autoencoder는 latent variable을 가진 generative model의 MLE로 해석할 수 있다.
즉, 굉장히 큰 $h$값 하나를 선택하여 아래 식을 근사한다고 볼 수 있다 (왜지...?).
$$
\log p_{model}(x) = \log \sum_h p_{model} (x, h)
$$
그렇다면 아래의 식을 최대화 하는 꼴이 된다.
$$
\log p_{model}(h, x) = \log p_{model}(h) + \log p_{model}(x|h)
$$
따라서 $p(h)$ 부분이 sparsity penalty에 해당한다.


### 14.2.2 Denoising Autoencoders
Sparse autoencoder처럼 penalty 항을 더하는 대신 loss 함수를 바꾸어 학습을 제어하는 방법도 있다.
Denoising autoencoder는 잡을을 더한 입력을 원본으로 복구하도록 학습된다.
$$
L(x, g(f(\tilde{x})))
$$
이 과정에서 denoising autoencoder는 잡을을 제외한 자료의 구조를 학습하게 된다.
따라서 데이터셋의 유용한 성질들을 학습할 수 있다.


### 14.2.3 Regularizing by Penalizing Derivatives
Sparse autoencoder와는 다르게 latent의 미분을 penalty로 사용하는 방법도 있다.
$$
L(x, g(f(x))) + \lambda \sum_i \vert\vert\nabla_xh_i\vert\vert^2
$$
이러한 penalty를 사용하면 입력의 조그만 변화에 대해 변하지 않는 latent를 얻게 된다.


## 14.3 Representational Power, Layer Size and Depth
많은 경우 하나의 hidden layer만 있는 autoencoder를 사용한다.
하지만 autoencoder도 순방향 신경망의 한 종류이기 때문에 층이 많아질수록 얻을 수 있는 이점이 있다.
- 보편근사정리에 따르면 hidden layer가 하나만 있어도 임의의 함수를 근사할 수 있다. 하지만, autoencoder의 관점에서 encoder와 decoder가 너무 얕으면 여러가지 제약을 적용하기 어렵다.
- 깊이가 깊어질수록 어떤 함수를 표현하기 위한 계산 비용이 지수적으로 줄어든다.
- 깊이가 깊어질수록 필요한 학습 데이터의 양이 지수적으로 줄어든다.
- 깊은 autoencoder가 더 나은 압축 성능을 보이는것이 실험적으로 증명되었다 (Hinton and Salakhutdinov, 2006).


## 14.4 Stochastic Encoders and Decoders
Autoencoder도 순방향 신경망의 한 종류이다.
따라서 순방향 신경망의 loss 함수를 설계했던 방법을 그대로 적용할 수 있다.
1. 순방향 신경망의 목표는 입력 $x$, 목표 출력 $y$에 대하여 $p(y|x)$를 최대화 하는 것.
    - 또는 $-\log p(y|x)$를 최소화
2. 모델의 목표에 따라 $p(y|x)$ 분포를 설정한 후 $-\log p(y|x)$를 loss로 사용하여 최소화.
    - 예를들어 출력이 연속적인 값이면 Gaussian을 선택 -> MSE loss

Autoencoder의 경우 입력과 목표 출력 모두 $x$인 경우인데, decoder 입장에서 다음과 같이 쓸 수 있다.
$$
\min[-\log p_{decoder}(x|h)]
$$
따라서, autoencoder에서도 모델의 목표에 따라 분포를 Gaussian, Bernoulli, ... 등으로 선택하면 loss 함수를 자연스레 유도할 수 있다.

Autoencoder가 확률론 관점에서 기존의 순방향 신경망과 다른 점은 encoder와 decoder의 확률 분포를 다음처럼 나누어 쓸 수 있다는 것이다.
$x$와 $h$의 어떤 결합 분포 $p_{model}(h, x)$에 대하여
- $p_{encoder}(h|x) = p_{model}(h|x)$
- $p_{decoder}(x|h) = p_{model}(x|h)$

단, 일반적으로 encoder와 decoder의 조건부 분포가 어떤 유일한 결합 분포 $p_{model}(h, x)$와 연결될 필요는 없다.
Denoising autoencoder의 경우 근사적으로 encoder와 decoder의 조건부 분포가 하나의 결함 분포와 연결되도록 학습되는 것이 밝혀졌다 (Alain et al; 2015).