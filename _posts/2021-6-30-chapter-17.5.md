# 17.5

## 17.5 The Challenge of Mixing between Separated Modes

MCMC를 사용할 때 가장 곤란한 점은 두 'mode'가 잘 섞이지 않는다는 것이다(특히 차원이 높은 공간에서 더 취약하다). 

- 마르코브 체인을 통해 샘플링 된 변수 $\boldsymbol x^{(t-1)}$은 에너지 $E(\boldsymbol x^{(t-1)})$에 따라 $\boldsymbol x^{(t)}$로 이동하는데, 일반적으로 $E(\boldsymbol x^{(t)})$는 $E(\boldsymbol x^{(t-1)})$보다 작거나 같기 때문에 $\boldsymbol x^{(t)}$는 점점 에너지가 낮은 영역으로 이동하게 된다.
- 이렇게 에너지가 낮은 영역을 'mode'라 부르고 상대적으로 에너지가 낮기 때문에 에너지 장벽에 막혀서 다른 mode로 넘어가기 힘들다.
- ![_config.yml]({{ site.baseurl }}/assets/ch17/Fig17_1.png)

위의 그림처럼 하나의 mode만 있는 경우에는 크게 문제가 되지 않는다.(다만, 변수들의 correlation이 높을수록 초기 위치에서 벗어나기 어렵다.) 하지만, 세번째 그림과 같이 mode가 여러개인 경우에는 처음 정해진 mode에서 벗어나기 어려운 것을 볼 수 있다.

이런 현상은 잠재 변수 $\boldsymbol h$를 가지는 모델에서도 자주 일어난다.

확률분포 $p(\boldsymbol x, \boldsymbol h)$
$$에서 $\boldsymbol x$라는 변수를 샘플링 하기 위해 $p(\boldsymbol x\vert \boldsymbol h)$와 $p(\boldsymbol h\vert \boldsymbol x)$에서 번갈아 가며 샘플링하는 경우가 많다. 여러 mode가 잘 섞이기 위해서는 $p(\boldsymbol h\vert \boldsymbol x)$의 엔트로피가 높아야 하고, $\boldsymbol h$가 좋은 representation을 가지려면 $\boldsymbol x$와 $\boldsymbol h$ 사이의 상호의존정보가 높아야 할 것이다. 하지만 이 둘은 동시에 일어날 수 없다.

![_config.yml]({{ site.baseurl }}/assets/ch17/Fig17_2.png)

왼쪽 그림처럼 볼츠만 머신을 사용한 경우에는 슬로우 믹싱이 일어난 것을 볼 수 있다.

### 17.5.1 Tempering to Mix between Modes

슬로우 믹싱은 확률분포가 뾰족할 때 잘 일어난다. 이때 '온도'라는 개념을 사용하면 좀 더 정확한(다양한) 샘플링이 가능하다. 기존의 에너지 기반 모델의 확률 분포는 아래와 같이 정의 되었는데

$$p(\boldsymbol x) \sim \exp(-E(\boldsymbol x))$$

여기에 추가적인 파라미터 $\beta$(온도에 반비례)를 도입하여 아래와 같이 정의 할 수 있다.

$$p(\boldsymbol x) \sim \exp(-\beta E(\boldsymbol x))$$

즉, 온도가 낮으면 확률 분포가 더 뾰족하고, 온도가 높을 수록 평평 하다. 

온도를 이용하여 mode사이의 믹싱이 일어 날 수 있도록 해주는 여러가지 방법이 존재한다.

- Tempered transition(Neal, 1994) : 높은 온도에서 시작하여 여러 mode 사이의 믹싱이 일어나게 한 후에 온도를 1로 조정하여 샘플링하는 방법.
- Parallel tempering(Iba, 2001) : 서로 다른 state들을 서로 다른 온도에서 병렬로 마르코브 체인을 수행하고, 각 iteration마다 메트로 폴리스 알고리즘에 따라 서로 다른 온도의 샘플을 서로 바꾼다.

    ![_config.yml]({{ site.baseurl }}/assets/ch17/Parallel_tempering.png)

    ([https://www.researchgate.net/figure/Schematic-of-the-parallel-tempering-method-for-fitting-the-model-In-parallel-tempering_fig6_276922924](https://www.researchgate.net/figure/Schematic-of-the-parallel-tempering-method-for-fitting-the-model-In-parallel-tempering_fig6_276922924))

    ### 17.5.2 Depth May Help Mixing

    잠재 변수를 사용하는 모델을 사용할 때 $\boldsymbol x$부터 $\boldsymbol h$까지의 깊이를 깊게하면 믹싱에 도움을 준다고 한다. 두 샘플을 인코딩 했을 때 만들어진 두 잠재 변수는 서로 떨어져 있어야 구분이 가능하기 때문에 많은 샘플들을 구분하기 위해서는 $\boldsymbol h$의 분포가 잠재 변수 공간에 고르게 분포하여야 한다. 이때 인코딩의 깊이가 깊어질수록 더 고르게 분포하는 경향이 있고, 이는 잠재 변수 공간에서의 마르코브 체인의 믹싱이 잘 일어나게 도와준다.