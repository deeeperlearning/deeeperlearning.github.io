# 제목 없음

### 12.1.4 Model Compression

상용 프로그램들은 일반인이 사용하기 때문에 작동 시간과 메모리 코스트가 낮아야한다. 그렇기 때문에 기존의 무거운 모델을 대체하는 작은 모델이 필요할 수 있다. 

모델 압축은 오버피팅을 방지하기 위해 모델 사이즈를 키운 경우 적용가능하다. 이 모델들의 사이즈가 커진 이유는 제한된 학습 데이터의 수 때문인데, 이렇게 커진 모델을 가지고 학습 데이터를 늘릴 수 있다면 더 작은 모델로 학습이 가능해진다. 

- 사이즈가 큰 모델은 결국 어떤 함수 $f(\boldsymbol x)$를 학습하게 되는데, 우리가 랜덤하게 $\boldsymbol x$를 뽑아서 학습된 $f$에 넣어주면, 새로운 데이터를 얻을 수 있다.
    - 나중에 사용할 테스트 input의 분포에 맞게 $\boldsymbol x$를 뽑는것이 효율이 좋기에, 기존 training input에 결함을 주거나 generative 모델을 사용하여 $\boldsymbol x$를 구하는 것이 좋다.

처음부터 작은 모델로 학습하는 방법도 있지만, 잘못된 클래스에 대한 사후 분포를 학습할 수 있기 때문에 좋지 않다.

### 12.1.5 Dynamic Structure

데이터 처리 시스템을 가속화 하기 위해서는 입력을 처리하는데 필요한 계산을 설명하는 그래프에 동적 구조를 갖는 시스템을 구축해야 한다. 

- 입력이 주어졌을 때 실행되어야하는 많은 신경망의 하위 집합을 데이터 처리 시스템이 동적으로 결정하게 할수도 있고,
- 개별 신경망이 주어진 정보를 계산할 하위 집합 (hidden units)을 결정하여 내부적으로 동적 구조를 나타낼 수도 있다.

만약 레어한 물체(또는 이벤트)를 찾는 것이 목적이라면 굉장히 정교하고 큰 용량을 가진 분류기가 필요하다. 그러나 여러개의 분류기를 연속적으로 사용하면 더 효율적으로 학습이 가능하다.

1. 작은 용량을 가진 첫 분류기는 높은 recall값을 가지도록, 즉, 레어 오브젝트가 있는 입력을 최대한 버리지 않도록 학습한다.
2. 마지막 분류기는 높은 precision값을 가지도록 학습한다. 

이렇게 일련의 분류기를 사용하게 되면 레어 오브젝트가 없는 입력은 초기에 배제시킬 수 있기 때문에 데이터 처리를 가속화 시킬 수 있다.

또 다른 동적 구조로는 

- 게이터라는 신경망을 사용하여 입력이 주어지면 여러 전문가 네트워크 중 어느 것이 출력을 계산하는 데 사용할 것인지 선택하는 방법.
- 스위치를 사용하여, hidden unit이 문맥에 따라 다른 unit으로부터 입력을 받도록 하는 방법이 있다.

동적 구조화 된 시스템을 사용할 때 한 가지 문제점은 시스템이 서로 다른 입력에 대해 서로 다른 코드 branch를 따르기 때문에, 병렬화가 힘들어 진다는 것이다.

### 12.1.6 Specialized Hardware Implementations of Deep Networks

CPU 및 GPU에 대한 소프트웨어 구현은 일반적으로 부동 소수점 숫자를 나타낼 때 32 또는 64 비트의 정밀도를 사용하지만, inference를 할 때에는 더 낮은 정밀도를 사용해도 된다는 것이 오랫동안 알려져 왔다(숫자당 적은 bit를 사용해도 된다면 하드웨어 표면적이 줄어든다). 또한 GPU가 보여주었듯이 하드웨어의 성능이 딥러닝에 끼치는 영향은 크다.

따라서 일반인이 휴대폰과 같은 저전력 장치에서 딥러닝을 사용할 수 있도록 특수 하드웨어를 구축하는 것은 중요한 일이다.