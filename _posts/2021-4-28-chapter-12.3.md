## 12.3 Speech Recognition


- Spoken natural language가 포함된 acoustic signal을 이에 해당하는 단어 배열로 변환하는 작업


  - 일반적으로 신호를 20ms 단위로 나눈 벡터를 이용함


- 1980년대에서 2012년까지 주로 hidden Markov models (HMMs)과 Gaussian mixture models (GMMs)이 결합된 시스템을 사용함


  - HMM은 음소의 배열에 대해 모델링

  - GMM은 acoustic feature와 음소 사이의 관계를 모델링


- 최근까지도 automatic speech recognition (ASR) 분야에 GMM-HMM 시스템이 주로 사용되었지만, 신경망이 처음으로 사용되기 시작한 분야 중 하나이기도 함


  - 1990년대에는 TIMIT에 대해 26%의 음소 감지 에러률을 달성 (Garofolo et al., 1993)

  - TIMIT (Acoustic-Phonetic Continuous Speech Corpus): 사물 인식에서의 MNIST와 비슷한 음성 신호 데이터베이스

  - 하지만 GMM-HMM 시스템도 여전히 높은 성능을 보여, 2000년대 후반까지도 신경망은 GMM-HMM이 커버하지 못하는 용도를 찾는 정도로만 쓰였음


- 하지만 더 크고 깊은 신경망의 사용이 가능해지며, 2009년부터는 음성 인식에 대한 비지도 학습에 사용되어 옴


  - Restricted Boltzmann machines (RBM; Part III)을 이용한 비지도 pretraining을 이용해 음소 감지 에러률이 26 $\rightarrow$ 20.7%로 감소 (Mohamed et al., 2009)

  - 이후 다양한 연구들이 진행되며 급격히 발전함

    - 예) TIMIT에서 초점을 둔 단순 음소 인식에서, 많은 양의 데이터에서부터 학습한 단어 사이의 배열에 대한 코딩으로 발전 (Dahl et al., 2012)


- 이후 점차 많은 양의 데이터가 이용 가능해지며, 굳이 비지도 pretraining 없이도 높은 성능을 보이게 됨


  - 특히 CNN을 사용하여 가중치가 시간, 주파수에 대해 중복 적용(replicate)되며, 초기 신경망에서 시간에 대해서만 가중치가 중복 적용 될 때보다 개선됨

  - Input spectrogram을 1차원 벡터가 아니라, 시간과 주파수 축에 대한 2차원 이미지로 처리하여 이미지 학습과 유사한 형태가 됨

  - 또한 deep LSTM RNN이 적용되며 음소 감지 에러률이 17.7%로 감소함.
