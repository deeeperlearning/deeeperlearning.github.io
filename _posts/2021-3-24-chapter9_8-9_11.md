# 9.8~9.11

# # 9.8 Efficient Convolution Algorithms

- 현재 사용되는 신경망 알고리즘들은 굉장히 많은 수의 유닛으로 이루어져 있다. GPU 병렬처리를 통해 계산을 수행하지만, convolution 계산 알고리즘 자체를 잘 선택하여 계산의 효율성을 높일 수 있다.
- 하나의 방법으로는 Fourier transform(FT)을 이용할 수 있다.
    - Convolution은 커널과 함수를 주파수 영역으로 변환한 후 곱하고 다시 inverse FT 한것과 같다 (항상 같은건 아니고 제약조건이 있긴 하다).
    - 커널과 함수의 크기에 따라 이 방법은 연산량이 낮은 경우가 있다.
- 또 다른 방법으로는 외적을 이용하는 것이다.
    - $d$ 차원의 커널을 $d$개의 벡터들의 외적으로 표현할 수 있는 경우가 있다 (separalbe이라고 부름).
    - 이 경우 $d$ 차원 커널을 이용해 convolution을 하는 것 보다 벡터들을 이용해 1차원 convolution을 한 후 결합하는 것이 더 효율적이다.
- Convolution을 더 빠르게 계산하는 방법이나, 정확도를 떨어뜨리지 않고 근사하는 방법은 활발히 연구되는 주제 중 하나이다.

## 9.9 Random or Unsupervised Features

CNN 역시 학습 과정에 가장 많은 시간이 소요된다. 이 장에서는 이 문제에 대한 해결법 몇 가지를 소개한다.

1. Random initialize
    - 말 그대로 CNN의 커널을 무작위로 형성한다.
    - 실제로 CNN 커널은 무작위로 가중치로 초기화 한 후 pooling에 무작위로 가중치를 부여하면 층들이 자연스럽게 주파수를 선택하고 translational invariant하게 작동하는 것을 확인한 연구도 있다.
2. 사람이 커널 설계
    - 특정 모양을 검출하는 등의 커널을 사람이 직접 설계하는 방법이다.
3. 비지도학습의 판정조건 이용
    - 어떤 연구에서는 작은 이미지 패치들을 k-means clustering으로 클러스터링 한 후 각 클러스터의 무게중심을 커널로 사용했다 (비슷한 이미지들끼리 모은 후 그 모양 검출하는 커널을 썼다는 이야기인 듯).
    - 이렇게 역전파가 아닌 비지도학습의 판정조건을 이용해서 커널을 형성할수도 있다.
    - 3부에서 자세히 설명한다고 한다.
4. 층별로 나누어 학습
    - 역전파를 한꺼번에 하는게 아니라 층별로 하는 방법도 있다. 8장에서 소개한 greedy layer-wise training 처럼 첫번째 층에 분류기를 붙여서 먼저 학습한 후 계산된 feature로부터 다음 층을 학습한다. 이 과정을 반복하여 깊은 모델을 쌓는 방법.
    - 3부에서는 이를 비지도학습의 판정조건을 이용하는 방법으로 확장하여 설명한다고 한다. 이러한 구조의 대표적인 예는 convolutional deep belief networks라고 한다.

## 9.10 The Neuroscientiﬁc Basis for Convolutional Networks

CNN은 생물학적인 뇌의 구조에서 영감을 받았다.

- 고양이의 뇌에서 뉴런이 시각자극에 반응하는 패턴을 보면, 특정 뉴런들은 몇 가지 특이한 이미지 패턴들에 대하여 크게 반응하는 반면 다른 자극에 대하여는 거의 반응하지 않았다.
- 이러한 결과에 영감을 받아 CNN을 만들게 되었다.

조금 더 구체적으로 CNN과 생물학적 뇌의 공통점을 살펴보자. 뇌에는 시각 정보를 본격적으로 처리하기 시작하는 1차 시각 피질(V1)이라는 부위가 있는데, CNN의 설계에는 다음과 같은 V1의 성질을 반영하였다.

- V1은 망막의 이미지 구조를 반영하는 2차원 구조.
- V1의 대부분은 단순세포로 이루어져 있는데, 이 세포들은 이미지의 국소 부분에 대해 거의 선형적으로 활성화된다(어느 정도까지는).
- V1에는 복합세포도 있는데, 이 세포의 활성화는 feature의 작은 위치적 이동에는 불변성을 가진다. 이는 CNN의 pooling layer에 영감을 주었다.

또, CNN의 마지막 층(classifier를 말하는 듯)은 특정 feature에만 반응한다. 실제로 뇌의 하측두피질(IT 피질)에도 특정 개념에만 반응하는 세포들이 있다. 한 가지 예로 할머니와 관련된 자극에만 반응하는 할머니 세포라는 것도 있다.

물론 CNN이 생물의 뇌와 다른점도 있다.

- 사람의 시야는 아주 작은 부분을 제외하고 해상도가 아주 낮다. 눈은 잦은 눈동자 움직임을 통해 얻은 정보들을 합성해 시야 전체가 선명하게 보인다고 믿게 만든다. 반면 CNN은 고해상도 이미지를 통째로 입력받는다.
- 사람의 시각체계는 다른 여러 감각기관과 통합되어 있고 생각 같은 다른 요인들이 영향을 미친다. 하지만 CNN은 아니다.
- 사람의 시각체계는 물체 인식을 제외하고도 여러가지 일을 수행한다. 또, 몸이 세상과 상호작용하는데 필요한 풍부한 3차원 정보를 처리한다. 이러한 구조를 가진 CNN을 사용하는 경우도 있지만 대부분은 아니다.
- V1같은 낮은 level의 영역도 더 높은 level의 영역으로부터의 feedback에 크게 영향을 받는다. 이러한 구조를 CNN에도 적용하려는 연구가 있지만, 큰 성능개선을 이룬적은 없다.
- IT 피질에서 포착하는 feature가 CNN에서 포착하는 feature와 비슷하긴 하지만, 중간층에서도 그러한지 밝혀지지는 않았다. 실제 사람의 뇌에서는 convolution과 pooling 연산을 사용하지 않을지도 모른다.
- 생물학의 뇌에서 시작정보를 처리하는 부분과 CNN의 학습방법은 굉장히 다르다.

실제 뇌의 V1 세포들의 가중치를 가보르 함수로 표현할 수 있다. 이 함수와 CNN 첫 layer의 가중치들을 비교해보면 인식하는 feature들이 비슷하다. 물론 이 사실 하나만으로 사람의 시각 체계를 모델링하는데 CNN이 가장 적합하다고 주장할 수는 없겠지만, 어느정도 작동 원리가 비슷하긴 하다.

## 9.11 Convolutional Networks and the History of Deep Learning

- 딥러닝의 역사에서 CNN은 생물학적인 발견을 잘 모델링 한 대표적인 예이다.
- CNN이 만들어진 후 많은 공모전에서 CNN이 우승했으며 역전파로 훈련해서 잘 작동하게 만든 최초의 신경망이다.
- 물론 일반적인 신경망이 잘 안되는 영역에서 CNN이 잘 작동하는 이유는 밝혀지지 않았다.
    1. 그냥 weight sharing을 하기 때문에 계산 면에서 효율적이기 때문이 수도 있고,
    2. 신경망이 클수록 잘 훈련하기 쉽기 때문일 수도 있다.
- 어찌되었건 CNN은 수십 년 전부터 좋은 성과를 냈으며 grid 구조를 가지는 데이터에 잘 작동하도록 신경망을 특수화하는 좋은 방법이다.
