## Chapter 17. Monte Carlo Methods

- 무작위화 알고리즘(randomized algorithm)은 크게 라스베가스, 몬테카를로 알고리즘 두 가지로 나뉨

  - 라스베가스 알고리즘은 항상 정확히 맞는 답을 내놓거나, 실패했다고 보고함

    - 이로 인해 랜덤한 양의 자원(메모리, 시간 등)을 사용함

  - 반면, 몬테카를로 알고리즘은 랜덤한 양의 에러가 더해진 대략적인 답을 내놓음

    - 에러의 양은 일반적으로 많은 자원을 사용할수록 줄어듬

- 기계학습에서 마주치는 정확한 답을 맞추기에 너무 어려운 문제의 경우엔, 정확한 결정적인(deterministic) 라스베가스 알고리즘 보다는, 대략적인(approximate) 몬테카를로 알고리즘을 쓰는 것이 좋음
   
  - 두 방법 모두 기계학습에서 널리 사용되는데, 이번 단원에서는 몬테카를로 방법에 초점을 둠


## 17.1 Sampling and Monte Carlo Methods

- 기계학습의 많은 기법들은 어떠한 확률 분포에서 샘플을 만들고, 이를 이용해 원하는 지표의 몬테카를로 추정(estimate)를 얻음


### 17.1.1 Why Sampling?

- 확률 분포에서 샘플을 뽑는 이유로, 작은 연산 양으로도 많은 덧셈이나 적분의 값을 유동적으로 가늠할 수 있게함

  - 그렇지 않다면 알고리즘에 포함되는 수많은 복잡한 덧셈과 적분 값을 일일이 계산해야함
    
  - 예) 일부 minibatch의 학습 비용을 샘플링해서 대략적인 평균 수치를 가늠함

  - 따라서 학습 분포에서 샘플링 할 수 있도록 모델을 학습시키는 것은 많은 기계학습 문제의 목표임


### 17.1.2 Basics of Monte Carlo Sampling

- 덧셈이나 적분이 항의 개수가 너무 많은 등의 이유로 정확히 계산될 수 없을 때, 몬테카를로 샘플링으로 얻은 평균으로 근사값을 구할 수 있음

  - 적분 $s$에 대해, 확률분포 $p$로부터 $n$개의 샘플 $x^{1}$, ..., $x^{n}$을 샘플링해 평균값을 구함

![_config.yml]({{ site.baseurl }}/assets/ch17/Eq17_1_2.PNG)
![_config.yml]({{ site.baseurl }}/assets/ch17/Eq17_3.PNG)

  - 특징 1) Estimator $\hat{s}$는 unbiased 되어있음

![_config.yml]({{ site.baseurl }}/assets/ch17/Eq17_4.PNG)

  - 특징 2) 큰 수의 법칙(law of large numbers)에 의해 만약 $x^i$가 i.i.d. 라면 평균 값은 기대값에 수렴하므로, $\hat{s}_{n}$의 분산은 $n$이 커질수록 감소함 (단, $f(x^i)<\infty$ 일 때) 

    - 큰 수의 법칙: 큰 모집단에서 무작위로 뽑은 표본의 평균이 전체 모집단의 평균과 가까울 가능성이 높다는 통계와 확률 분야의 기본 개념

![_config.yml]({{ site.baseurl }}/assets/ch17/Eq17_5.PNG)
![_config.yml]({{ site.baseurl }}/assets/ch17/Eq17_6_7.PNG)

- 한 편, 확률분포 $p(x)$에서 샘플링하는 것이 어려울수도 있음

  - 대신 사용할 수 있는 방법으로 importance 샘플링이 있음 (17.2에서 소개)

  - 보다 일반적인 방법으로는 몬테카를로 마르코브 체인이 있음 (17.3에서 소개)


## 17.2 Importance Sampling

- $p(x)$, $f(x)$를 각각 얻어낼 수 없을 때, 아래와 같은 식으로 식을 변형해 $q$, $pf/q$를 샘플링 할 수도 있음

![_config.yml]({{ site.baseurl }}/assets/ch17/Eq17_8.PNG)

- Importance sampling estimator의 기대값은 유지되어 $q$에 영향을 받지 않음

![_config.yml]({{ site.baseurl }}/assets/ch17/Eq17_9.PNG)
![_config.yml]({{ site.baseurl }}/assets/ch17/Eq17_10.PNG)
![_config.yml]({{ site.baseurl }}/assets/ch17/Eq17_11.PNG)

- 하지만 분산은 $q$를 어떻게 선택하는지에 따라 예민하게 바뀜

![_config.yml]({{ site.baseurl }}/assets/ch17/Eq17_12.PNG)

  - 따라서 분산을 최소화하도록 최적화된 $q$는 아래와 같음 ($Z$: normalization constant)

![_config.yml]({{ site.baseurl }}/assets/ch17/Eq17_13.PNG)

- 만약 $f(x)$의 부호가 바뀌지 않는다면, $Var[\hat{s}_{q*}]=0$ 인 경우 단 하나의 샘플이면 충분하다는 뜻이됨

  - 단, 이는 $q*$를 선택함으로써 원래의 문제가 완전히 풀려버렸다는 뜻으로, 일반적으로 발생하는 경우는 아님

- $p$, $q$가 정규화되어 있지 않다면, biased importance sampling이 됨 ($\tilde{p}, \tilde{q}$: Unnormalized form, $\mathbb{E}(\hat{s}_{BIS}) \neq s$)

![_config.yml]({{ site.baseurl }}/assets/ch17/Eq17_14_16.PNG)

- $q$를 잘 선택하면 몬테카를로 샘플링의 효율을 크게 향상 시킬 수 있지만, 잘못 선택하면 오히려 안 좋아짐

  - $p \mid f \mid /q$ 항을 고려하면, $q$가 $p$, $f$보다 훨씬 작을 때 분산이 커지게 됨

  - 한 편, $q(x)$가 너무 커지면, $pf/q$가 0이나 너무 작은 수가 되어 쓸모없는 샘플들을 뽑게됨

- 이러한 장애물이 있음에도 기계학습의 전반적인 분야에서 널리 쓰이는 기술임 (많은 수의 단어에 대한 언어 모델 등)

  - 18, 20단원에서 자세히 소개 될 예정임
