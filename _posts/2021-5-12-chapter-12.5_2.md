### 12.5.2 Knowledge Representation, Reasoning and Question Answering

딥러닝을 이용한 문장 번역등은 문자나 단어에 대한 임배딩을 사용하면서 굉장히 성공적으로 작동하였다. 이러한 임배딩은 문자나 단어 하나에 대한 개념을 표현한다. 최근에는 단어나 문자 하나에 대한 임배딩을 넘어 관계나 지식 자체에 대한 임배딩 방법을 연구한다 (대표적인 예로 검색엔진).

관계를 딥러닝으로 학습하기 위해서는 관계를 표현하는 학습 데이터와 이를 표현하기에 적절한 모델이 필요하다. 우선 관계를 표현하기에 적합한 학습 데이터의 형태부터 생각해보자.

**관계 학습 데이터**

관계라는 개념을 조금 더 구체적으로 기술하기 위해서는 entity와 관계(또는 지식)을 triplet으로 묶어 표현해야 한다. 아래 예시를 보면 이해가 쉽다.

- 두 entity 사이의 관계를 triplet으로 표현 → (entity1, relation, entity2)
- E.g. (1, is less than, 2)

조금 더 확장해서 어떤 entity 하나에 대한 관계(넓은 의미에서의)를 attribute로 표현할수도 있다.

- tuple로 표현 → (entity, attribute)
- E.g. (dog, has fur)

이런 관계나 성질을 저장하는데에 특수화 된 관계형 데이터베이스들도 이미 많이 개발되어 있다.

- Freebase , OpenCyc, WordNet, Wikibase, ...

**관계 학습 모델**

관계의 학습에는 자연어 처리 모델들이 흔하게 사용된다. 구체적인 예시들은 다음과 같다.

- 언어를 모델링하는것과 지식을 학습하는 것은 굉장히 비슷하므로, 관계형 데이터베이스의 데이터와 자연어 문장을 함께 학습 (Bordes et al., 2011, 2012; Wang et al., 2014a). 또는 여러 관계형 데이터베이스의 데이터를 한꺼번에 학습 (Bordes et al., 2013b).
- Entity들을 벡터로 표현하고 관계는 행렬로 표현하여 학습. 이렇게 하면 관계라는것이 entity에 가해지는 operation처럼 생각할 수 있다 (Bordes et al., 2012).
- Link prediction: 관계형 데이터베이스의 데이터를 이용해 학습한 다음 누락된 관계를 예측하여 새로운 사실을 알아내는 방법 (Wang et al. (2014b), Lin et al. (2015), Garcia-Duran et al. (2015)).
    - 이러한 모델은 평가하기가 굉장히 까다롭다. 만약 어떤 링크가 데이터에는 없는데 모델의 예측으로는 존재해야 한다면, 진짜 없는건지 데이터에 누락된것인지 알기가 어렵다.
    - 한가지 방법은 거짓일 확률이 높은 관계에 대해 모델을 테스트하는 것이다. 예를들어 참인 관계 (entity1, relation1, entity2)에서 entity2를 데이터베이스의 랜덤한 entity로 바꾸면 이 관계는 거짓일 확률이 높다.
- Word-sense disambiguation: 문맥상 단어의 느낌을 추론하는 task도 관계의 학습에 포함된다 (Navigli and Velardi, 2005; Bordes et al., 2012).

궁극적으로는 모델이 reasoning process를 하는것이 가능하고, natural language에 대해 충분한 이해가 있다면 general question answering system을 만들 수 있다. 물론 굉장히 어려운 문제이다.
